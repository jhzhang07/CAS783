{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jhzhang07/CAS783/blob/master/COMPAS_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "id": "oeAmg28R5bo9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/CAS783/')\n",
        "PROJECT_PATH = \"/content/drive/MyDrive/CAS783/\""
      ],
      "metadata": {
        "id": "4SB9WwgA7A_s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install --upgrade pip"
      ],
      "metadata": {
        "id": "ZYfSCzfl90qI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install -r \"/content/drive/MyDrive/CAS783/requirements.txt\""
      ],
      "metadata": {
        "id": "oPcrnkQb7IhX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sX451uLs5ShS"
      },
      "outputs": [],
      "source": [
        "\n",
        "from adversarial_models import *\n",
        "from utils import *\n",
        "from get_data import *\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import lime\n",
        "import lime.lime_tabular\n",
        "import shap\n",
        "from copy import deepcopy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class racist_model_f:\n",
        "    def predict(self, X):\n",
        "        return np.array([params.negative_outcome if x[race_indc] > 0 else params.positive_outcome for x in X])\n",
        "\n",
        "    def predict_proba(self, X):\n",
        "        return one_hot_encode(self.predict(X))\n",
        "\n",
        "    def score(self, X, y):\n",
        "        return np.mean(self.predict(X) == y)\n",
        "\n",
        "class innocuous_model_psi:\n",
        "    def predict_proba(self, X):\n",
        "        return one_hot_encode(np.array([params.negative_outcome if x[unrelated_indcs] > 0 else params.positive_outcome for x in X]))\n",
        "\n",
        "class innocuous_model_psi_two:\n",
        "    def predict_proba(self, X):\n",
        "        A = np.where(X[:, unrelated_indcs] > 0, params.positive_outcome, params.negative_outcome)\n",
        "        B = np.where(X[:, unrelated_indcs1] > 0, params.positive_outcome, params.negative_outcome)\n",
        "        preds = np.logical_xor(A, B).astype(int)\n",
        "        return one_hot_encode(preds)\n",
        "\n",
        "def experiment_main():\n",
        "    params = Params(\"/content/drive/MyDrive/CAS783/model_configurations/experiment_params.json\")\n",
        "    np.random.seed(params.seed)\n",
        "    X, y, cols = get_and_preprocess_compas_data(params)\n",
        "\n",
        "    X['unrelated_column_one'] = np.random.choice([0, 1], size=X.shape[0])\n",
        "    X['unrelated_column_two'] = np.random.choice([0, 1], size=X.shape[0])\n",
        "\n",
        "    features = [c for c in X]\n",
        "    race_indc = features.index('race')\n",
        "    unrelated_indcs = features.index('unrelated_column_one')\n",
        "    unrelated_indcs1 = features.index('unrelated_column_two')\n",
        "    X = X.values\n",
        "\n",
        "    xtrain, xtest, ytrain, ytest = train_test_split(X, y, test_size=0.1)\n",
        "    ss = StandardScaler().fit(xtrain)\n",
        "    xtrain = ss.transform(xtrain)\n",
        "    xtest = ss.transform(xtest)\n",
        "\n",
        "    print('=====================')\n",
        "    print(\"Starting LIME experiments on COMPAS dataset...\")\n",
        "    print('=====================')\n",
        "\n",
        "    adv_lime = Adversarial_Lime_Model(racist_model_f(), innocuous_model_psi()).train(\n",
        "        xtrain, ytrain,\n",
        "        categorical_features=[features.index('unrelated_column_one'), features.index('unrelated_column_two'), features.index('c_charge_degree_F'), features.index('c_charge_degree_M'), features.index('two_year_recid'), features.index('race'), features.index(\"sex_Male\"), features.index(\"sex_Female\")],\n",
        "        feature_names=features, perturbation_multiplier=30)\n",
        "\n",
        "    adv_explainer = lime.lime_tabular.LimeTabularExplainer(\n",
        "        xtrain, sample_around_instance=True, feature_names=adv_lime.get_column_names(),\n",
        "        categorical_features=[features.index('unrelated_column_one'), features.index('unrelated_column_two'), features.index('c_charge_degree_F'), features.index('c_charge_degree_M'), features.index('two_year_recid'), features.index('race'), features.index(\"sex_Male\"), features.index(\"sex_Female\")],\n",
        "        discretize_continuous=False)\n",
        "\n",
        "    explanations = [adv_explainer.explain_instance(xtest[i], adv_lime.predict_proba).as_list() for i in range(xtest.shape[0])]\n",
        "\n",
        "    print(\"\\n[ LIME Results - Single Unrelated Column ]\")\n",
        "    print(experiment_summary(explanations, features))\n",
        "    print(\"Model Fidelity:\", round(adv_lime.fidelity(xtest), 2))\n",
        "\n",
        "    adv_lime = Adversarial_Lime_Model(racist_model_f(), innocuous_model_psi_two()).train(\n",
        "        xtrain, ytrain,\n",
        "        categorical_features=[features.index('unrelated_column_one'), features.index('unrelated_column_two'), features.index('c_charge_degree_F'), features.index('c_charge_degree_M'), features.index('two_year_recid'), features.index('race'), features.index(\"sex_Male\"), features.index(\"sex_Female\")],\n",
        "        feature_names=features, perturbation_multiplier=30)\n",
        "\n",
        "    adv_explainer = lime.lime_tabular.LimeTabularExplainer(\n",
        "        xtrain, feature_names=adv_lime.get_column_names(),\n",
        "        categorical_features=[features.index('unrelated_column_one'), features.index('unrelated_column_two'), features.index('c_charge_degree_F'), features.index('c_charge_degree_M'), features.index('two_year_recid'), features.index('race'), features.index(\"sex_Male\"), features.index(\"sex_Female\")],\n",
        "        discretize_continuous=False)\n",
        "\n",
        "    explanations = [adv_explainer.explain_instance(xtest[i], adv_lime.predict_proba).as_list() for i in range(xtest.shape[0])]\n",
        "\n",
        "    print(\"\\n[ LIME Results - Two Unrelated Columns ]\")\n",
        "    print(experiment_summary(explanations, features))\n",
        "    print(\"Model Fidelity:\", round(adv_lime.fidelity(xtest), 2))\n",
        "\n",
        "    print('=====================')\n",
        "    print(\"Launching SHAP evaluation...\")\n",
        "    print('=====================')\n",
        "\n",
        "    background_distribution = shap.kmeans(xtrain, 10)\n",
        "\n",
        "    adv_shap = Adversarial_Kernel_SHAP_Model(racist_model_f(), innocuous_model_psi()).train(\n",
        "        xtrain, ytrain, feature_names=features)\n",
        "\n",
        "    adv_kerenel_explainer = shap.KernelExplainer(adv_shap.predict, background_distribution)\n",
        "    explanations = adv_kerenel_explainer.shap_values(xtest)\n",
        "\n",
        "    formatted_explanations = [[(features[i], exp[i]) for i in range(len(exp))] for exp in explanations]\n",
        "\n",
        "    print(\"\\n[ SHAP Results - Single Unrelated Column ]\")\n",
        "    print(experiment_summary(formatted_explanations, features))\n",
        "    print(\"Model Fidelity:\", round(adv_shap.fidelity(xtest), 2))\n",
        "\n",
        "    background_distribution = shap.kmeans(xtrain, 10)\n",
        "\n",
        "    adv_shap = Adversarial_Kernel_SHAP_Model(racist_model_f(), innocuous_model_psi_two()).train(\n",
        "        xtrain, ytrain, feature_names=features)\n",
        "\n",
        "    adv_kerenel_explainer = shap.KernelExplainer(adv_shap.predict, background_distribution)\n",
        "    explanations = adv_kerenel_explainer.shap_values(xtest)\n",
        "\n",
        "    formatted_explanations = [[(features[i], exp[i]) for i in range(len(exp))] for exp in explanations]\n",
        "\n",
        "    print(\"\\n[ SHAP Results - Two Unrelated Columns ]\")\n",
        "    print(experiment_summary(formatted_explanations, features))\n",
        "    print(\"Model Fidelity:\", round(adv_shap.fidelity(xtest), 2))\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    experiment_main()"
      ],
      "metadata": {
        "id": "_Pz9Kr8fYfE6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "lime_one_feature = {\n",
        "    1: {'unrelated_column_one': 1.0},\n",
        "    2: {\n",
        "        'c_charge_degree_F': 0.10679611650485436,\n",
        "        'c_charge_degree_M': 0.11488673139158576,\n",
        "        'length_of_stay': 0.006472491909385114,\n",
        "        'priors_count': 0.008090614886731391,\n",
        "        'race': 0.22006472491909385,\n",
        "        'sex_Female': 0.1650485436893204,\n",
        "        'sex_Male': 0.16990291262135923,\n",
        "        'two_year_recid': 0.11326860841423948,\n",
        "        'unrelated_column_two': 0.09546925566343042\n",
        "    },\n",
        "    3: {\n",
        "        'age': 0.014563106796116505,\n",
        "        'c_charge_degree_F': 0.12297734627831715,\n",
        "        'c_charge_degree_M': 0.11974110032362459,\n",
        "        'length_of_stay': 0.014563106796116505,\n",
        "        'priors_count': 0.019417475728155338,\n",
        "        'race': 0.2297734627831715,\n",
        "        'sex_Female': 0.10517799352750809,\n",
        "        'sex_Male': 0.0825242718446602,\n",
        "        'two_year_recid': 0.1343042071197411,\n",
        "        'unrelated_column_two': 0.156957928802589\n",
        "    }\n",
        "}\n",
        "\n",
        "lime_two_features = {\n",
        "    1: {\n",
        "        'c_charge_degree_F': 0.012944983818770227,\n",
        "        'c_charge_degree_M': 0.008090614886731391,\n",
        "        'length_of_stay': 0.0048543689320388345,\n",
        "        'race': 0.011326860841423949,\n",
        "        'sex_Female': 0.01779935275080906,\n",
        "        'sex_Male': 0.0372168284789644,\n",
        "        'two_year_recid': 0.009708737864077669,\n",
        "        'unrelated_column_one': 0.4773462783171521,\n",
        "        'unrelated_column_two': 0.42071197411003236\n",
        "    },\n",
        "    2: {\n",
        "        'age': 0.003236245954692557,\n",
        "        'c_charge_degree_F': 0.05339805825242718,\n",
        "        'c_charge_degree_M': 0.06796116504854369,\n",
        "        'priors_count': 0.006472491909385114,\n",
        "        'race': 0.04692556634304207,\n",
        "        'sex_Female': 0.06796116504854369,\n",
        "        'sex_Male': 0.05501618122977346,\n",
        "        'two_year_recid': 0.038834951456310676,\n",
        "        'unrelated_column_one': 0.3284789644012945,\n",
        "        'unrelated_column_two': 0.33171521035598706\n",
        "    },\n",
        "    3: {\n",
        "        'age': 0.008090614886731391,\n",
        "        'c_charge_degree_F': 0.09061488673139159,\n",
        "        'c_charge_degree_M': 0.10194174757281553,\n",
        "        'length_of_stay': 0.0048543689320388345,\n",
        "        'priors_count': 0.014563106796116505,\n",
        "        'race': 0.10679611650485436,\n",
        "        'sex_Female': 0.18932038834951456,\n",
        "        'sex_Male': 0.15048543689320387,\n",
        "        'two_year_recid': 0.11165048543689321,\n",
        "        'unrelated_column_one': 0.10194174757281553,\n",
        "        'unrelated_column_two': 0.11974110032362459\n",
        "    }\n",
        "}\n",
        "\n",
        "shap_one_feature = {\n",
        "    1: {\n",
        "        'age': 0.0048543689320388345,\n",
        "        'length_of_stay': 0.06957928802588997,\n",
        "        'unrelated_column_one': 0.9255663430420712\n",
        "    },\n",
        "    2: {\n",
        "        'age': 0.06310679611650485,\n",
        "        'c_charge_degree_M': 0.0016181229773462784,\n",
        "        'length_of_stay': 0.3155339805825243,\n",
        "        'priors_count': 0.05825242718446602,\n",
        "        'race': 0.45792880258899676,\n",
        "        'two_year_recid': 0.021035598705501618,\n",
        "        'unrelated_column_one': 0.0744336569579288,\n",
        "        'unrelated_column_two': 0.008090614886731391\n",
        "    },\n",
        "    3: {\n",
        "        'age': 0.24919093851132687,\n",
        "        'c_charge_degree_F': 0.008090614886731391,\n",
        "        'c_charge_degree_M': 0.0048543689320388345,\n",
        "        'length_of_stay': 0.2977346278317152,\n",
        "        'priors_count': 0.16181229773462782,\n",
        "        'race': 0.2087378640776699,\n",
        "        'sex_Female': 0.014563106796116505,\n",
        "        'sex_Male': 0.009708737864077669,\n",
        "        'two_year_recid': 0.022653721682847898,\n",
        "        'unrelated_column_two': 0.022653721682847898\n",
        "    }\n",
        "}\n",
        "\n",
        "shap_two_features = {\n",
        "    1: {\n",
        "        'age': 0.03398058252427184,\n",
        "        'length_of_stay': 0.24433656957928804,\n",
        "        'priors_count': 0.038834951456310676,\n",
        "        'race': 0.2669902912621359,\n",
        "        'unrelated_column_one': 0.1796116504854369,\n",
        "        'unrelated_column_two': 0.23624595469255663\n",
        "    },\n",
        "    2: {\n",
        "        'age': 0.05501618122977346,\n",
        "        'c_charge_degree_M': 0.003236245954692557,\n",
        "        'length_of_stay': 0.06310679611650485,\n",
        "        'priors_count': 0.032362459546925564,\n",
        "        'race': 0.28802588996763756,\n",
        "        'sex_Male': 0.0016181229773462784,\n",
        "        'unrelated_column_one': 0.2766990291262136,\n",
        "        'unrelated_column_two': 0.27993527508090615\n",
        "    },\n",
        "    3: {\n",
        "        'age': 0.05501618122977346,\n",
        "        'c_charge_degree_F': 0.011326860841423949,\n",
        "        'c_charge_degree_M': 0.0016181229773462784,\n",
        "        'length_of_stay': 0.09223300970873786,\n",
        "        'priors_count': 0.043689320388349516,\n",
        "        'race': 0.1941747572815534,\n",
        "        'sex_Female': 0.0048543689320388345,\n",
        "        'sex_Male': 0.008090614886731391,\n",
        "        'two_year_recid': 0.024271844660194174,\n",
        "        'unrelated_column_one': 0.3122977346278317,\n",
        "        'unrelated_column_two': 0.2524271844660194\n",
        "    }\n",
        "}\n",
        "\n",
        "colors = {\n",
        "    'S2': '#D9534F',\n",
        "    'Unrelated1': '#5BC0DE',\n",
        "    'Unrelated2': '#0275D8',\n",
        "    'Others': '#D3D3D3'\n",
        "}\n",
        "\n",
        "def plot_attack(axs, results, method_name):\n",
        "    titles = ['Biased Classifier f', 'Attack 1 Feature', 'Attack 2 Features']\n",
        "    datasets = [results['biased'], results['attack1'], results['attack2']]\n",
        "    for idx, data in enumerate(datasets):\n",
        "        for rank in [1, 2, 3]:\n",
        "            ax = axs[rank-1, idx]\n",
        "            vals = data[rank]\n",
        "            s2 = 0\n",
        "            unrelated1 = 0\n",
        "            unrelated2 = 0\n",
        "            others = 0\n",
        "            for feat, pct in vals.items():\n",
        "                if feat == 'race' or feat == 'sex_Female' or feat == 'sex_Male':\n",
        "                    s2 += pct\n",
        "                elif feat == 'unrelated_column_one':\n",
        "                    unrelated1 += pct\n",
        "                elif feat == 'unrelated_column_two':\n",
        "                    unrelated2 += pct\n",
        "                else:\n",
        "                    others += pct\n",
        "            ax.barh(0, s2, color=colors['S2'])\n",
        "            ax.barh(0, unrelated1, left=s2, color=colors['Unrelated1'])\n",
        "            ax.barh(0, unrelated2, left=s2+unrelated1, color=colors['Unrelated2'])\n",
        "            ax.barh(0, others, left=s2+unrelated1+unrelated2, color=colors['Others'])\n",
        "            ax.set_xlim(0, 1)\n",
        "            ax.set_yticks([])\n",
        "            if rank == 1:\n",
        "                ax.set_title(titles[idx])\n",
        "    for ax in axs.flat:\n",
        "        ax.label_outer()\n",
        "\n",
        "fig, axs = plt.subplots(3, 3, figsize=(12, 6))\n",
        "lime_results = {\n",
        "    'biased': {1: {'S2': 1.0}, 2: {}, 3: {}},\n",
        "    'attack1': lime_one_feature,\n",
        "    'attack2': lime_two_features\n",
        "}\n",
        "plot_attack(axs, lime_results, \"LIME\")\n",
        "handles = [\n",
        "    plt.Rectangle((0,0),1,1, color=colors['S2'], label='S2'),\n",
        "    plt.Rectangle((0,0),1,1, color=colors['Unrelated1'], label='Unrelated Column 1'),\n",
        "    plt.Rectangle((0,0),1,1, color=colors['Unrelated2'], label='Unrelated Column 2'),\n",
        "    plt.Rectangle((0,0),1,1, color=colors['Others'], label='Others')\n",
        "]\n",
        "axs[0,0].legend(handles=handles, loc='lower right', fontsize=8)\n",
        "plt.suptitle(\"Figure 1: LIME\", fontsize=16)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "fig, axs = plt.subplots(3, 3, figsize=(12, 6))\n",
        "shap_results = {\n",
        "    'biased': {1: {'S2': 1.0}, 2: {}, 3: {}},\n",
        "    'attack1': shap_one_feature,\n",
        "    'attack2': shap_two_features\n",
        "}\n",
        "plot_attack(axs, shap_results, \"SHAP\")\n",
        "handles = [\n",
        "    plt.Rectangle((0,0),1,1, color=colors['S2'], label='S2'),\n",
        "    plt.Rectangle((0,0),1,1, color=colors['Unrelated1'], label='Unrelated Column 1'),\n",
        "    plt.Rectangle((0,0),1,1, color=colors['Unrelated2'], label='Unrelated Column 2'),\n",
        "    plt.Rectangle((0,0),1,1, color=colors['Others'], label='Others')\n",
        "]\n",
        "axs[0,0].legend(handles=handles, loc='lower right', fontsize=8)\n",
        "plt.suptitle(\"Figure 2: SHAP\", fontsize=16)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "yO5D_tYaj2n5"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "dylanvenv",
      "language": "python",
      "name": "dylanvenv"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}